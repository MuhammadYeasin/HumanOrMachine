{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f237f98e-502c-4af3-8f49-98156c015f88",
   "metadata": {},
   "source": [
    "# HumanOrMachine : Detecting AI-Generated Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c94f3f-c1da-4c3c-bdb0-ac0ff4e6cce0",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "This project focuses on developing a binary classifier to distinguish between human-written and AI-generated text. As large language models become increasingly sophisticated, the ability to differentiate between human and machine-generated content is becoming an important technological challenge. This notebook documents my approach to building an automated system that can identify the source of a given text.\n",
    "\n",
    "## Dataset Description\n",
    "For this project, I've created a dataset consisting of:\n",
    "\n",
    "1. **Human-generated texts**: A collection of jokes from Reddit's r/jokes subreddit, focusing specifically on music-related humor. These posts were created by human users and represent natural human writing patterns, humor structures, and linguistic choices.\n",
    "\n",
    "2. **AI-generated texts**: A parallel dataset of AI-generated jokes using similar prompts and themes. These were created using large language models to mimic human-written jokes but contain subtle patterns and characteristics unique to AI generation.\n",
    "\n",
    "Both datasets contain structured joke content with titles and punchlines, providing a balanced comparison between human and machine text generation capabilities.\n",
    "\n",
    "## Repository Information\n",
    "All code, datasets, and additional resources for this project are available on my GitHub repository:\n",
    "https://github.com/MuhammadYeasin/HumanOrMachine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35457aa-2bd1-4892-8b14-dc898dcbf47d",
   "metadata": {},
   "source": [
    "## Dataset Collection and Preprocessing\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "### Human-Generated Text\n",
    "The human-generated portion of our dataset consists of jokes collected from Reddit's r/jokes subreddit. I specifically focused on music-related jokes to maintain thematic consistency with the AI-generated counterparts. Each joke includes:\n",
    "\n",
    "- **Title**: The setup for the joke\n",
    "- **Selftext**: The body/punchline of the joke\n",
    "- **Metadata**: Creation timestamp, score (upvotes), and post ID\n",
    "\n",
    "This data represents authentic human writing with natural humor patterns, linguistic quirks, and creative structures that evolved organically within an online community.\n",
    "\n",
    "### AI-Generated Text\n",
    "For the machine-generated portion, I used a large language model to create jokes following similar prompts. The generation process involved:\n",
    "\n",
    "- Extracting titles from the human jokes dataset\n",
    "- Using these titles as prompts for the language model\n",
    "- Collecting the AI-generated punchlines\n",
    "- Structuring the data to match the format of the human dataset\n",
    "\n",
    "This approach ensures that both datasets cover similar topics and themes, making the classification task focus on writing style and patterns rather than content differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b3e91-d2e6-49a8-a742-bd16b66c4743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
